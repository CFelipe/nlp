\documentclass[12pt, a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[left=3.00cm,
            right=2.00cm,
            top=3.00cm,
            bottom=2.00cm]{geometry}
\usepackage[brazilian]{babel} % Hifenização e dicionário
\usepackage{enumitem}         % Para itemsep etc
\usepackage{zi4}              % Para fonte de códigos
\usepackage{listings}         % Para códigos
\usepackage{lstautogobble}    % Códigos indentados corretamente
\usepackage{color}            % Para coloração de códigos
\usepackage{mathpazo}         % Palatino
\usepackage{parskip}          % Linha em branco entre parágrafos em vez de recuo
\usepackage{verbatim}         % Para comentários
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage[breaklinks]{hyperref}

\DeclareGraphicsExtensions{.pdf,.png}

\newcommand{\code}[1]{{\lstinline{#1}}}

\usepackage{listings}
\lstset{
    autogobble=true,
    columns=fullflexible,
    showspaces=false,
    showtabs=false,
    breaklines=true,
    showstringspaces=false,
    breakatwhitespace=true,
    escapeinside={(*@}{@*)},
    basicstyle=\ttfamily\footnotesize,
    frame=l,
    framesep=12pt,
    xleftmargin=12pt,
    tabsize=4,
    captionpos=b,
    belowskip=-0.3 \baselineskip
}

\begin{document}
\begin{center}
    \textsc{Universidade Federal do Rio Grande do Norte} \\
    \textsc{Departamento de Informática e Matemática Aplicada}
\end{center}

\bigskip

\begin{tabular}{@{}rl@{}}
    \emph{Disciplina} & Processamento de Linguagem Natural \\
    \emph{Docente}    & Carlos Augusto Prolo \\
    \emph{Discente}   & Felipe Cortez de Sá \\
\end{tabular}

\bigskip

\begin{center}
\large Extração de gramática
\end{center}

\section{Introdução}
Este relatório descreve a implementação de um programa para extrair a gramática
de um corpus e convertê-la para a \emph{Chomsky Normal Form}.

\section{Programa}
O programa foi desenvolvido utilizando a linguagem de programação Python 3
apenas com as bibliotecas padrão, sendo elas \code{argparse} para tratar
argumentos de linha de comando e \code{collections} para contar a frequência de
cada regra.


\subsection{Uso}
Para rodar o programa, digite na linha de comandos

\begin{lstlisting}[language=bash]
$ python3 grammar.py input_file [-m "pre" | "post"] 
\end{lstlisting}

em que \code{input_file} é o arquivo do corpus contendo a gramática que se
deseja extrair.

A flag \code{-m} é utilizada para imprimir as regras pré ou pós conversão para
CNF. Caso seja omitida, o padrão é a impressão das regras convertidas.

As regras são escritas na saída padrão \code{stdout}.

\section{Conversão para forma normal de Chomsky}
Foi utilizado o corpus \code{traindata-TOP}, garantindo que há
uma regra base que serve como símbolo \code{START}. 

\subsection{Terminais}
O método \code{cnf_term} cria, para cada terminal, uma regra não-terminal no formato
\code{TERM_NT -> TERM}. As ocorrências de terminais nas produções são então
substituídas pelos não-terminais criados.

\subsection{Binarização}
O método \code{cnf_bin} transforma regras com mais de dois não-terminais no lado direito
em múltiplas regras, cada uma com dois não-terminais no lado direito.

Para a regra \code{NP -> DT_NT NN_NT CC_NT NN_NT NN_NT}, por exemplo, temos

\begin{lstlisting}[columns=fixed]
NP   -> DT_NT NP_1
NP_1 -> NN_NT NP_2
NP_2 -> CC_NT NP_3
NP_3 -> NN_NT NN_NT
\end{lstlisting}


\section{Resultados}
As 1000 regras mais comuns aparecem 690502 vezes dentre um total de 783701
produ\-ções, cobrindo 88.10\% do corpus, e podem ser vistas no arquivo
\code{grammar.txt}. As regras na forma normal de Chomsky encontram-se no arquivo
\code{grammar-cnf.txt}

\end{document}
